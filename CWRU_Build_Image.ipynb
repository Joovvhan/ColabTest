{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CWRU_Build_Image.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/ColabTest/blob/master/CWRU_Build_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ih-sCHd-PVso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataPath = 'D:/Case Western Reserve University Bearing Data'\n",
        "savePath = dataPath\n",
        "\n",
        "folders = ['Normal Baseline Data', '12k Drive End Bearing Fault Data',\n",
        "           'Fan-End Bearing Fault Data', '48k Drive End Bearing Fault Data']\n",
        "\n",
        "sensPos = 'DE'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_f-Icn_RQd4q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StBoV4grQyiE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matFileList = list()\n",
        "\n",
        "# for i in range(len(folders)):\n",
        "for i in range(2):\n",
        "    if (i == 0):\n",
        "        searchWord = dataPath + '/' + folders[i] + '/' + '*.mat'\n",
        "    else:\n",
        "        searchWord = dataPath + '/' + folders[i] + '/' + 'B' + '*.mat'\n",
        "    \n",
        "    file = glob.glob(searchWord)\n",
        "    matFileList = matFileList + file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiKjXibspIHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'Xception'\n",
        "pretrainedModel = 'ResNet50'\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 8\n",
        "verb = 1\n",
        "\n",
        "fs = 12000\n",
        "nsc = 448\n",
        "nov = np.floor(nsc/2)\n",
        "nff = nsc\n",
        "imgSize = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFByTvA9TN1C",
        "colab_type": "code",
        "outputId": "f28d17ef-a716-4e53-b75f-a66f976e5d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(matFileList)):\n",
        "    \n",
        "    x = sio.loadmat(matFileList[i])\n",
        "    \n",
        "    imgNpy = matFileList[i].replace('.mat', '_image.npy')\n",
        "    imgNpy = savePath + '/' + imgNpy.split('\\\\')[-1]\n",
        "    \n",
        "    keyName = [key for key in x.keys() if sensPos in key][0]\n",
        "    \n",
        "    data = x[keyName].flatten()\n",
        "    \n",
        "    Pxx, _, _, _ = plt.specgram(data, NFFT=nff, Fs=fs, noverlap=nov, \n",
        "                                window=np.hamming(nsc), cmap='viridis')\n",
        "    plt.close()\n",
        "\n",
        "    Sxx = 10 * np.log10(Pxx)\n",
        "    \n",
        "    imgs = np.zeros([250, imgSize, imgSize])\n",
        "    \n",
        "    for count, j in enumerate(np.arange(0, Sxx.shape[1] - imgSize, (Sxx.shape[1] - imgSize) / 250)):\n",
        "        newStep = int(j)\n",
        "        imgs[count, :, :] = Sxx[1:, newStep:newStep+imgSize]\n",
        "#       print(newStep)\n",
        "                   \n",
        "    np.save(imgNpy, imgs)\n",
        "    \n",
        "    print('Build {}'.format(imgNpy))\n",
        "    print('Image Size: {}'.format(imgs.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build D:/Case Western Reserve University Bearing Data/Normal_0_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/Normal_1_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/Normal_2__image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/Normal_3_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B007_0_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B007_1_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B007_2_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B007_3_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B014_0_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B014_1_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B014_2_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B014_3_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B021_0_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B021_1_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B021_2_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B021_3_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B028_0_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B028_1_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B028_2_image.npy\n",
            "Image Size: (250, 224, 224)\n",
            "Build D:/Case Western Reserve University Bearing Data/B028_3_image.npy\n",
            "Image Size: (250, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbQqtJVCWI_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "npyFileList = glob.glob(savePath + '/' + '*.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ToExPZJRVOBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "npyFileList\n",
        "\n",
        "normalFile = [file for file in npyFileList if 'Normal' in file]\n",
        "\n",
        "b028File = [file for file in npyFileList if '28' in file]\n",
        "\n",
        "trainingRatio = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WBjmOUqcnfxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(normalFile)):\n",
        "    imgs = np.load(normalFile[i])\n",
        "    if i == 0:\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])       \n",
        "        \n",
        "for i in range(len(b028File)):\n",
        "    imgs = np.load(b028File[i])\n",
        "    if i == 0:\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0jHG2FgYoZhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a809a8ea-ed4b-4379-bfc0-15f43ef60899"
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LACp1cCuoo7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ae2ab7b7-1892-4c53-a125-9b514ad0fb61"
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -66.24364602940754\n",
            "Standard Deviation of Training Image: 21.740762182297097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z81NoEAuoqvv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGJ_HIr0oszt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d2ef1a6e-041c-4abc-b97e-6936aa4f7e4d"
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v92I0ONsou66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d60b409b-43ca-4b0e-ce2a-566fdcbdf844"
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IpYpX-GjoycG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8cda9fef-a922-4976-aea6-4f6a73678970"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "    \n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "    \n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "    \n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "              \n",
        "elif pretrainedModel == 'ResNet50':\n",
        "    \n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "              \n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "    \n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "                      \n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "              \n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "              \n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "    \n",
        "              \n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "              \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\주환\\appdata\\local\\conda\\conda\\envs\\paper\\lib\\site-packages\\keras_applications\\resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bISY5lg6qhV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "8f14edaa-f2cd-4cfe-d8ca-cdbc4facc754"
      },
      "cell_type": "code",
      "source": [
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 81s 51ms/step - loss: 0.0761 - acc: 0.9925 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 1.1045e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            " 544/1600 [=========>....................] - ETA: 42s - loss: 1.0960e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QuJVp2PlqkgF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DC9svm3ZqnyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format('Normal', 'B028', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(savePath + '/{}'.format(modelSaved))\n",
        "    np.save(savePath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(savePath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}