{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Autoencoder MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Joovvhan/ColabTest/blob/master/Keras_Autoencoder_MNIST.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "dju32qW3-eIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_SDT6Bg9-nqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ifio7Sq-zTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DEC-MGBS-5bt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBLTVo3e-6XS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8dZM1KJI-_JQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "33994a99-3a3d-4dc4-ac5f-221b101aeb6d"
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "chhu2QOj-_y-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        },
        "outputId": "a8733ca4-9f4e-4a10-dbc7-c6a3b177130b"
      },
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.3595 - val_loss: 0.2720\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.2660 - val_loss: 0.2565\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.2453 - val_loss: 0.2316\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.2225 - val_loss: 0.2120\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.2070 - val_loss: 0.1997\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1964 - val_loss: 0.1905\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1882 - val_loss: 0.1831\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1814 - val_loss: 0.1769\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1755 - val_loss: 0.1713\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1702 - val_loss: 0.1664\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1655 - val_loss: 0.1618\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1612 - val_loss: 0.1577\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1572 - val_loss: 0.1540\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1536 - val_loss: 0.1505\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1503 - val_loss: 0.1473\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1473 - val_loss: 0.1443\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1445 - val_loss: 0.1416\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1420 - val_loss: 0.1392\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1396 - val_loss: 0.1369\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1375 - val_loss: 0.1349\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1354 - val_loss: 0.1328\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1335 - val_loss: 0.1308\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1316 - val_loss: 0.1289\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1298 - val_loss: 0.1272\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1280 - val_loss: 0.1255\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1263 - val_loss: 0.1237\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1247 - val_loss: 0.1221\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1231 - val_loss: 0.1207\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1216 - val_loss: 0.1191\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1202 - val_loss: 0.1177\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1188 - val_loss: 0.1164\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1175 - val_loss: 0.1152\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1163 - val_loss: 0.1140\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1152 - val_loss: 0.1129\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1141 - val_loss: 0.1119\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1131 - val_loss: 0.1109\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1122 - val_loss: 0.1101\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1114 - val_loss: 0.1092\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1106 - val_loss: 0.1085\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1099 - val_loss: 0.1078\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1092 - val_loss: 0.1072\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1086 - val_loss: 0.1066\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1080 - val_loss: 0.1060\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1075 - val_loss: 0.1056\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.1070 - val_loss: 0.1051\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1066 - val_loss: 0.1046\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1061 - val_loss: 0.1042\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1057 - val_loss: 0.1038\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1053 - val_loss: 0.1034\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1050 - val_loss: 0.1031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x277705e39e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "9ejUz_NT_OmZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_a7s_Zb_QNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99146a66-7e1e-46a0-e963-b0f2b0c8d3bb"
      },
      "cell_type": "code",
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VP2EpR0M_X0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "# add a Dense layer with a L1 activity regularizer\n",
        "encoded = Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-x5s-NS_YYb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvOf916P_bYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3653
        },
        "outputId": "39bc5c83-abb6-48c5-a437-77f4f7e0433a"
      },
      "cell_type": "code",
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.3421 - val_loss: 0.2630\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.2567 - val_loss: 0.2495\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.2438 - val_loss: 0.2394\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2343 - val_loss: 0.2260\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2218 - val_loss: 0.2135\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2094 - val_loss: 0.2021\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1974 - val_loss: 0.1902\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1866 - val_loss: 0.1823\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1784 - val_loss: 0.1726\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1707 - val_loss: 0.1654\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1652 - val_loss: 0.1616\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1608 - val_loss: 0.1587\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1570 - val_loss: 0.1538\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1538 - val_loss: 0.1509\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1507 - val_loss: 0.1481\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1481 - val_loss: 0.1455\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1460 - val_loss: 0.1437\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1440 - val_loss: 0.1425\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1424 - val_loss: 0.1405\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1408 - val_loss: 0.1384\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1392 - val_loss: 0.1368\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1375 - val_loss: 0.1348\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1358 - val_loss: 0.1336\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1342 - val_loss: 0.1325\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1325 - val_loss: 0.1308\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1313 - val_loss: 0.1289\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1299 - val_loss: 0.1279\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1288 - val_loss: 0.1270\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1277 - val_loss: 0.1260\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1265 - val_loss: 0.1257\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1257 - val_loss: 0.1244\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1248 - val_loss: 0.1260\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1240 - val_loss: 0.1212\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1232 - val_loss: 0.1210\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1225 - val_loss: 0.1237\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1218 - val_loss: 0.1201\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1210 - val_loss: 0.1186\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1203 - val_loss: 0.1178\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1196 - val_loss: 0.1187\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1189 - val_loss: 0.1161\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1181 - val_loss: 0.1153\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1172 - val_loss: 0.1186\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1166 - val_loss: 0.1147\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1158 - val_loss: 0.1134\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1154 - val_loss: 0.1137\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1144 - val_loss: 0.1124\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1141 - val_loss: 0.1119\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1135 - val_loss: 0.1118\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1130 - val_loss: 0.1118\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1126 - val_loss: 0.1093\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1120 - val_loss: 0.1119\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1117 - val_loss: 0.1095\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1113 - val_loss: 0.1085\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1110 - val_loss: 0.1080\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1106 - val_loss: 0.1096\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1103 - val_loss: 0.1092\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1099 - val_loss: 0.1089\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1094 - val_loss: 0.1119\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1092 - val_loss: 0.1085\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1090 - val_loss: 0.1075\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1085 - val_loss: 0.1070\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1083 - val_loss: 0.1069\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1078 - val_loss: 0.1071\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1077 - val_loss: 0.1080\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1073 - val_loss: 0.1056\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1071 - val_loss: 0.1066\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1068 - val_loss: 0.1066\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1066 - val_loss: 0.1057\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1062 - val_loss: 0.1031\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1060 - val_loss: 0.1050\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1057 - val_loss: 0.1051\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1055 - val_loss: 0.1045\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1053 - val_loss: 0.1050\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1050 - val_loss: 0.1034\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1047 - val_loss: 0.1032\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1045 - val_loss: 0.1044\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1044 - val_loss: 0.1026\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1040 - val_loss: 0.1032\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1040 - val_loss: 0.1033\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1036 - val_loss: 0.1013\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1035 - val_loss: 0.1019\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1032 - val_loss: 0.1040\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1031 - val_loss: 0.1030\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1029 - val_loss: 0.1027\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1027 - val_loss: 0.1018\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1025 - val_loss: 0.1009\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1024 - val_loss: 0.1028\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1022 - val_loss: 0.1021\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1019 - val_loss: 0.1021\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1018 - val_loss: 0.1003\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1017 - val_loss: 0.1006\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1013 - val_loss: 0.0997\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1014 - val_loss: 0.1005\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1011 - val_loss: 0.1007\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1009 - val_loss: 0.0989\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1009 - val_loss: 0.1006\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1007 - val_loss: 0.0998\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1006 - val_loss: 0.0988\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1004 - val_loss: 0.0997\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1003 - val_loss: 0.0999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2770fced5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "fy2_CPUD_gzE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xus1Hvud_hXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzOE-Apw_lE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        },
        "collapsed": true,
        "outputId": "5d5ef8eb-364d-433b-e7a4-cbbb33ff3ce0"
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.2185 - val_loss: 0.1727\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1564 - val_loss: 0.1462\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1402 - val_loss: 0.1295\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1315 - val_loss: 0.1249\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1258 - val_loss: 0.1205\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1217 - val_loss: 0.1190\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1186 - val_loss: 0.1160\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1161 - val_loss: 0.1147\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1142 - val_loss: 0.1124\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1123 - val_loss: 0.1089\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1111 - val_loss: 0.1150\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1097 - val_loss: 0.1073\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1089 - val_loss: 0.1063\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1083 - val_loss: 0.1043\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1072 - val_loss: 0.1070\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1066 - val_loss: 0.1063\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1059 - val_loss: 0.1063\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1054 - val_loss: 0.1068\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1048 - val_loss: 0.1055\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1045 - val_loss: 0.1028\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1039 - val_loss: 0.1013\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1036 - val_loss: 0.1016\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1032 - val_loss: 0.1010\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1030 - val_loss: 0.1022\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1025 - val_loss: 0.1028\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1018 - val_loss: 0.0986\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1017 - val_loss: 0.1000\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1017 - val_loss: 0.0972\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1014 - val_loss: 0.1002\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1011 - val_loss: 0.0986\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1007 - val_loss: 0.1029\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1006 - val_loss: 0.0996\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1003 - val_loss: 0.0969\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1001 - val_loss: 0.0993\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1001 - val_loss: 0.0970\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0998 - val_loss: 0.0981\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0997 - val_loss: 0.0984\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0995 - val_loss: 0.1000\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0992 - val_loss: 0.0998\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0993 - val_loss: 0.0986\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0992 - val_loss: 0.0996\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0991 - val_loss: 0.0963\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0987 - val_loss: 0.0970\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0987 - val_loss: 0.0986\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0984 - val_loss: 0.0960\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0982 - val_loss: 0.0964\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0983 - val_loss: 0.0971\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0983 - val_loss: 0.0981\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0981 - val_loss: 0.0989\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0977 - val_loss: 0.0966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x27888a74978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "UokC8xSb_pHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "2d8e0f0c-f1c4-49a5-ec77-211f1b7fd9cd"
      },
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 11\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Qef4qlWF_uWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "collapsed": true,
        "outputId": "6985f29c-6e89-46de-8f58-bc95f6f33af2"
      },
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(0, n):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-30-1b470ea85ada>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 32 into shape (4,32)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NnjOLrCGGdW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73bae2cb-1e32-45fa-bc89-3ab5c32e45f2"
      },
      "cell_type": "code",
      "source": [
        "encoded_imgs.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "eCR6smY0HPEL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEHb6rIvHPN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "0b70f27c-215b-4705-c2b2-1478de1566d3"
      },
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x144 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Xg3hae4N_vVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (7, 7, 32)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WznRD9Qh_8Zy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3653
        },
        "outputId": "3715b986-eb13-428a-dddf-3f5d6557c2ef"
      },
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1840 - val_loss: 0.1299\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1209 - val_loss: 0.1149\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1124 - val_loss: 0.1098\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1086 - val_loss: 0.1048\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1060 - val_loss: 0.1056\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1044 - val_loss: 0.1022\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1032 - val_loss: 0.1012\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1023 - val_loss: 0.1024\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1014 - val_loss: 0.0999\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1009 - val_loss: 0.0990\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1004 - val_loss: 0.0995\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1000 - val_loss: 0.0987\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0997 - val_loss: 0.0983\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0994 - val_loss: 0.0982\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0991 - val_loss: 0.0994\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0987 - val_loss: 0.0973\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0985 - val_loss: 0.0982\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0982 - val_loss: 0.0979\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0981 - val_loss: 0.0973\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0978 - val_loss: 0.0978\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0977 - val_loss: 0.0977\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0975 - val_loss: 0.0977\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0975 - val_loss: 0.0964\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0973 - val_loss: 0.0983\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0972 - val_loss: 0.0973\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0971 - val_loss: 0.0964\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0970 - val_loss: 0.0968\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0967 - val_loss: 0.0961\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0967 - val_loss: 0.0958\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0967 - val_loss: 0.0959\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0966 - val_loss: 0.0957\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0964 - val_loss: 0.0968\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0964 - val_loss: 0.0954\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0964 - val_loss: 0.0962\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0962 - val_loss: 0.0951\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0962 - val_loss: 0.0951\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0961 - val_loss: 0.0951\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0960 - val_loss: 0.0962\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0959 - val_loss: 0.0964\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0959 - val_loss: 0.0952\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0959 - val_loss: 0.0949\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0958 - val_loss: 0.0948\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0957 - val_loss: 0.0964\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0956 - val_loss: 0.0958\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0956 - val_loss: 0.0954\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0956 - val_loss: 0.0949\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0956 - val_loss: 0.0969\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0954 - val_loss: 0.0947\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0954 - val_loss: 0.0953\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0954 - val_loss: 0.0948\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0953 - val_loss: 0.0945\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0954 - val_loss: 0.0944\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0954 - val_loss: 0.0946\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0953 - val_loss: 0.0947\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0952 - val_loss: 0.0955\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0952 - val_loss: 0.0948\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0951 - val_loss: 0.0944\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0951 - val_loss: 0.0947\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0950 - val_loss: 0.0943\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0950 - val_loss: 0.0944\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0950 - val_loss: 0.0944\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0950 - val_loss: 0.0948\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0949 - val_loss: 0.0960\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0949 - val_loss: 0.0941\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0949 - val_loss: 0.0942\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0949 - val_loss: 0.0947\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0949 - val_loss: 0.0946\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0948 - val_loss: 0.0945\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0947 - val_loss: 0.0942\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0948 - val_loss: 0.0944\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0947 - val_loss: 0.0950\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0947 - val_loss: 0.0940\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0946 - val_loss: 0.0946\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0947 - val_loss: 0.0941\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0946 - val_loss: 0.0939\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0946 - val_loss: 0.0938\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0945 - val_loss: 0.0946\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0946 - val_loss: 0.0938\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0945 - val_loss: 0.0952\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0945 - val_loss: 0.0939\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0945 - val_loss: 0.0944\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0945 - val_loss: 0.0947\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0945 - val_loss: 0.0937\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0944 - val_loss: 0.0939\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0944 - val_loss: 0.0941\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0944 - val_loss: 0.0941\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0944 - val_loss: 0.0938\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0943 - val_loss: 0.0946\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0943 - val_loss: 0.0937\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0943 - val_loss: 0.0940\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0943 - val_loss: 0.0939\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0943 - val_loss: 0.0937\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0943 - val_loss: 0.0944\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0942 - val_loss: 0.0939\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0943 - val_loss: 0.0936\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0942 - val_loss: 0.0936\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0942 - val_loss: 0.0935\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0941 - val_loss: 0.0943\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0942 - val_loss: 0.0937\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0941 - val_loss: 0.0936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x27758814ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "ayWu2Zs-__YS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "c273bc2b-a53b-4634-de79-9f8dc9d08298"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, LSTM, RepeatVector\n",
        "from keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(timesteps, input_dim))\n",
        "encoded = LSTM(latent_dim)(inputs)\n",
        "\n",
        "decoded = RepeatVector(timesteps)(encoded)\n",
        "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
        "\n",
        "sequence_autoencoder = Model(inputs, decoded)\n",
        "encoder = Model(inputs, encoded)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-42-85f7d3e6bc04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'timesteps' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "j-4ogCti__tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "7a9b697b-ab9b-40d0-afba-c22fef3fd00e"
      },
      "cell_type": "code",
      "source": [
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "h = Dense(intermediate_dim, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_sigma = Dense(latent_dim)(h)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-43-9e785c714a43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mz_log_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0F5ujEqM__yN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                              mean=0., std=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMWIJ_uyAGSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_h = Dense(intermediate_dim, activation='relu')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PsIfPS74AGXn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# end-to-end autoencoder\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# encoder, from inputs to latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# generator, from latent space to reconstructed inputs\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(decoder_input)\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "generator = Model(decoder_input, _x_decoded_mean)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bh-nJN6JAGdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vae_loss(x, x_decoded_mean):\n",
        "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
        "    return xent_loss + kl_loss\n",
        "\n",
        "vae.compile(optimizer='rmsprop', loss=vae_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UHcAfbVoAGka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "vae.fit(x_train, x_train,\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kbFBGMeBAGq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkhwMYEYAO4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# display a 2D manifold of the digits\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# we will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-15, 15, n)\n",
        "grid_y = np.linspace(-15, 15, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]]) * epsilon_std\n",
        "        x_decoded = generator.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSvIsSQo-E_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### [1] [Building Autoencoders in Keras, The Keras Blog](https://blog.keras.io/building-autoencoders-in-keras.html)"
      ]
    }
  ]
}