{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Autoencoder MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Joovvhan/ColabTest/blob/master/Keras_Autoencoder_MNIST.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "dju32qW3-eIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82420e71-05d8-44e4-bbba-a25c76ed1b10"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_SDT6Bg9-nqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ifio7Sq-zTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DEC-MGBS-5bt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBLTVo3e-6XS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "46798325-62d8-494e-8ff9-1bf71fbf9640"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "9import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dZM1KJI-_JQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "11ef9343-693a-4841-8844-7a81241dc18f"
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "chhu2QOj-_y-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1832
        },
        "outputId": "ccfd2c47-5183-4092-f1ee-5d7f9993c761"
      },
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.3566 - val_loss: 0.2703\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.2621 - val_loss: 0.2499\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.2395 - val_loss: 0.2275\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.2204 - val_loss: 0.2108\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.2059 - val_loss: 0.1986\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1951 - val_loss: 0.1889\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1865 - val_loss: 0.1813\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1795 - val_loss: 0.1751\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1738 - val_loss: 0.1697\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1690 - val_loss: 0.1653\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1648 - val_loss: 0.1613\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1609 - val_loss: 0.1577\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1574 - val_loss: 0.1543\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1540 - val_loss: 0.1509\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1508 - val_loss: 0.1478\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1478 - val_loss: 0.1448\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1449 - val_loss: 0.1422\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.1423 - val_loss: 0.1395\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1398 - val_loss: 0.1372\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.1375 - val_loss: 0.1349\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1353 - val_loss: 0.1329\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1333 - val_loss: 0.1310\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1314 - val_loss: 0.1290\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1296 - val_loss: 0.1273\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1279 - val_loss: 0.1255\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1262 - val_loss: 0.1239\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1246 - val_loss: 0.1223\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1231 - val_loss: 0.1209\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1216 - val_loss: 0.1194\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1203 - val_loss: 0.1180\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1190 - val_loss: 0.1167\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1177 - val_loss: 0.1155\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1166 - val_loss: 0.1144\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1155 - val_loss: 0.1133\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1144 - val_loss: 0.1123\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1135 - val_loss: 0.1113\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1126 - val_loss: 0.1105\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1117 - val_loss: 0.1097\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1109 - val_loss: 0.1089\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1102 - val_loss: 0.1082\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1095 - val_loss: 0.1075\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1089 - val_loss: 0.1069\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1083 - val_loss: 0.1063\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1077 - val_loss: 0.1058\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1072 - val_loss: 0.1052\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1067 - val_loss: 0.1048\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1062 - val_loss: 0.1043\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.1057 - val_loss: 0.1039\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1053 - val_loss: 0.1035\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1049 - val_loss: 0.1031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33c932f358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "9ejUz_NT_OmZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_a7s_Zb_QNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "786c76fa-4e01-4f2f-b330-5040aa069136"
      },
      "cell_type": "code",
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f33c63985f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VP2EpR0M_X0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "# add a Dense layer with a L1 activity regularizer\n",
        "encoded = Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-x5s-NS_YYb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvOf916P_bYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3592
        },
        "outputId": "fe7eb5a7-5484-494f-e235-0e8db6f35823"
      },
      "cell_type": "code",
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.3429 - val_loss: 0.2622\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2546 - val_loss: 0.2437\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2319 - val_loss: 0.2211\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2125 - val_loss: 0.2031\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1971 - val_loss: 0.1890\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1865 - val_loss: 0.1840\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1801 - val_loss: 0.1759\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1748 - val_loss: 0.1710\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1697 - val_loss: 0.1652\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1655 - val_loss: 0.1612\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1614 - val_loss: 0.1597\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1576 - val_loss: 0.1559\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1545 - val_loss: 0.1511\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1517 - val_loss: 0.1499\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1492 - val_loss: 0.1483\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1468 - val_loss: 0.1450\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1448 - val_loss: 0.1470\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1429 - val_loss: 0.1392\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1410 - val_loss: 0.1387\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1393 - val_loss: 0.1386\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1378 - val_loss: 0.1358\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1364 - val_loss: 0.1349\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.1348 - val_loss: 0.1283\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1337 - val_loss: 0.1307\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.1325 - val_loss: 0.1307\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1316 - val_loss: 0.1297\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1306 - val_loss: 0.1307\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.1297 - val_loss: 0.1286\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1290 - val_loss: 0.1232\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1282 - val_loss: 0.1298\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1275 - val_loss: 0.1297\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1269 - val_loss: 0.1262\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1262 - val_loss: 0.1266\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1256 - val_loss: 0.1247\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1249 - val_loss: 0.1257\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1244 - val_loss: 0.1235\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1239 - val_loss: 0.1228\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1234 - val_loss: 0.1248\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1228 - val_loss: 0.1212\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1223 - val_loss: 0.1211\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1216 - val_loss: 0.1221\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.1212 - val_loss: 0.1160\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1209 - val_loss: 0.1183\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1203 - val_loss: 0.1199\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1199 - val_loss: 0.1183\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1193 - val_loss: 0.1187\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1190 - val_loss: 0.1167\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1186 - val_loss: 0.1198\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1182 - val_loss: 0.1173\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1178 - val_loss: 0.1156\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1175 - val_loss: 0.1145\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1172 - val_loss: 0.1157\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1167 - val_loss: 0.1164\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1166 - val_loss: 0.1157\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1161 - val_loss: 0.1177\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1158 - val_loss: 0.1165\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1156 - val_loss: 0.1148\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1151 - val_loss: 0.1157\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1147 - val_loss: 0.1137\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1145 - val_loss: 0.1118\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1141 - val_loss: 0.1125\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1140 - val_loss: 0.1129\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1136 - val_loss: 0.1097\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1134 - val_loss: 0.1140\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1130 - val_loss: 0.1099\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1130 - val_loss: 0.1110\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1126 - val_loss: 0.1114\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1124 - val_loss: 0.1120\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1121 - val_loss: 0.1141\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1118 - val_loss: 0.1114\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1117 - val_loss: 0.1091\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.1115 - val_loss: 0.1114\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.1112 - val_loss: 0.1148\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1111 - val_loss: 0.1119\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1108 - val_loss: 0.1124\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1106 - val_loss: 0.1105\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1104 - val_loss: 0.1103\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1102 - val_loss: 0.1119\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1102 - val_loss: 0.1075\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1100 - val_loss: 0.1070\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1097 - val_loss: 0.1096\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1093 - val_loss: 0.1060\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1095 - val_loss: 0.1089\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1092 - val_loss: 0.1120\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1089 - val_loss: 0.1072\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1090 - val_loss: 0.1085\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1090 - val_loss: 0.1117\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1085 - val_loss: 0.1081\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1084 - val_loss: 0.1087\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1085 - val_loss: 0.1056\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1082 - val_loss: 0.1091\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1083 - val_loss: 0.1083\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1080 - val_loss: 0.1072\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1078 - val_loss: 0.1067\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1078 - val_loss: 0.1060\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1075 - val_loss: 0.1070\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.1076 - val_loss: 0.1068\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.1072 - val_loss: 0.1110\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1073 - val_loss: 0.1062\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1071 - val_loss: 0.1072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33c6c02a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "fy2_CPUD_gzE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xus1Hvud_hXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzOE-Apw_lE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1491
        },
        "collapsed": true,
        "outputId": "4ac247b2-613d-4bbf-97ce-c2b79ff6d877"
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 85s 1ms/step - loss: 0.2173 - val_loss: 0.1652\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 85s 1ms/step - loss: 0.1580 - val_loss: 0.1481\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1435 - val_loss: 0.1427\n",
            "Epoch 4/50\n",
            " 9728/60000 [===>..........................] - ETA: 1:09 - loss: 0.1371"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3b6b3754a0be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UokC8xSb_pHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qef4qlWF_uWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xg3hae4N_vVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (7, 7, 32)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WznRD9Qh_8Zy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ayWu2Zs-__YS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, LSTM, RepeatVector\n",
        "from keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(timesteps, input_dim))\n",
        "encoded = LSTM(latent_dim)(inputs)\n",
        "\n",
        "decoded = RepeatVector(timesteps)(encoded)\n",
        "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
        "\n",
        "sequence_autoencoder = Model(inputs, decoded)\n",
        "encoder = Model(inputs, encoded)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-4ogCti__tm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "h = Dense(intermediate_dim, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_sigma = Dense(latent_dim)(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0F5ujEqM__yN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                              mean=0., std=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMWIJ_uyAGSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_h = Dense(intermediate_dim, activation='relu')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PsIfPS74AGXn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# end-to-end autoencoder\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# encoder, from inputs to latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# generator, from latent space to reconstructed inputs\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(decoder_input)\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "generator = Model(decoder_input, _x_decoded_mean)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bh-nJN6JAGdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vae_loss(x, x_decoded_mean):\n",
        "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
        "    return xent_loss + kl_loss\n",
        "\n",
        "vae.compile(optimizer='rmsprop', loss=vae_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UHcAfbVoAGka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "vae.fit(x_train, x_train,\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kbFBGMeBAGq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkhwMYEYAO4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# display a 2D manifold of the digits\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# we will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-15, 15, n)\n",
        "grid_y = np.linspace(-15, 15, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]]) * epsilon_std\n",
        "        x_decoded = generator.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSvIsSQo-E_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### [1] [Building Autoencoders in Keras, The Keras Blog](https://blog.keras.io/building-autoencoders-in-keras.html)"
      ]
    }
  ]
}