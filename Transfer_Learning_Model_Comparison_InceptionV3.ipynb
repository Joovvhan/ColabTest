{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Model Comparison.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Joovvhan/ColabTest/blob/master/Transfer_Learning_Model_Comparison_InceptionV3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a25ef7-8fd2-4059-bac1-9a95538e98c8"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dTd14pQF8sbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YA4w0qgn86O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c50d160-c35f-4ce7-d0f9-2194a5f53192"
      },
      "cell_type": "code",
      "source": [
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Model', 'Data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "StFo8tBm8-4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "\"\"\"\n",
        "folders = os.listdir(dataPath)\n",
        "\n",
        "for folder in folders:\n",
        "  files = os.listdir(dataPath + '/' + folder)\n",
        "  print(len(files))\n",
        "  print(files[-1])\n",
        "\"\"\"\n",
        "\n",
        "folderF1 = dataPath + '/' + 'A3F1P3'  \n",
        "folderF5 = dataPath + '/' + 'A3F5P3'\n",
        "filesF1 = os.listdir(folderF1)\n",
        "filesF5 = os.listdir(folderF5)\n",
        "\n",
        "folderA5 = dataPath + '/' + 'A5F3P3'\n",
        "filesA5 = os.listdir(folderA5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqSDKWm5WE2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edba7f0a-bee2-4c6b-c9ec-81dc3031502c"
      },
      "cell_type": "code",
      "source": [
        "filesF1[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A3.490879_F0.139398_P2.076554_H360.426598.wav'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "hVwdMUwTWnbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fs, dataInt16 = wf.read(folderF1 + '/' + filesF1[0])\n",
        "dataFloat = dataInt16 / (2 ** 15)\n",
        "\n",
        "fs, dataInt16 = wf.read(folderF5 + '/' + filesF5[0])\n",
        "dataFloat = dataInt16 / (2 ** 15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AZQiR1afrToE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Pxx, freqs, bins, _ = plt.specgram(dataFloat, NFFT=nff, Fs=fs, noverlap=nov, \\\n",
        "                                   window=np.hamming(nsc), cmap='viridis')\n",
        "plt.close()\n",
        "img = Pxx[0:224, :]\n",
        "\n",
        "plt.imshow(10*np.log10(img), cmap='viridis')\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LwVFaqAjV_a9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKdtQNWYAYpa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "572b8bd2-38f3-46fc-836f-0aab89f0b42b"
      },
      "cell_type": "code",
      "source": [
        "imgSize = 224\n",
        "imgsF1 = np.zeros([len(filesF1), imgSize, imgSize])\n",
        "\n",
        "for i in trange(len(filesF1)):\n",
        "    fs, dataInt16 = wf.read(folderF1 + '/' + filesF1[i])\n",
        "    dataFloat = dataInt16 / (2 ** 15)\n",
        "    Pxx, _, _, _ = plt.specgram(dataFloat, NFFT=nff, Fs=fs, noverlap=nov, \\\n",
        "                                       window=np.hamming(nsc), cmap='viridis')\n",
        "    plt.close()\n",
        "    imgsF1[i, :, :] = 10 * np.log10(Pxx[0:224, :])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [09:21<00:00,  1.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db9953de-db23-4db7-b8c7-acc5a7ff7660"
      },
      "cell_type": "code",
      "source": [
        "imgsF5 = np.zeros([len(filesF5), imgSize, imgSize])\n",
        "\n",
        "for i in trange(len(filesF5)):\n",
        "    fs, dataInt16 = wf.read(folderF5 + '/' + filesF5[i])\n",
        "    dataFloat = dataInt16 / (2 ** 15)\n",
        "    Pxx, _, _, _ = plt.specgram(dataFloat, NFFT=nff, Fs=fs, noverlap=nov, \\\n",
        "                                       window=np.hamming(nsc), cmap='viridis')\n",
        "    plt.close()\n",
        "    imgsF5[i, :, :] = 10 * np.log10(Pxx[0:224, :])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [09:24<00:00,  1.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainIdxF1 = np.random.choice(len(imgsF1) - 1, int(len(imgsF1) * 0.8), replace=False)\n",
        "testIdxF1 = list(set(range(0, len(imgsF1))) - set(trainIdxF1))\n",
        "\n",
        "trainImgsF1 = imgsF1[trainIdxF1, :, :]\n",
        "testImgsF1 = imgsF1[testIdxF1, :, :]\n",
        "\n",
        "trainIdxF5 = np.random.choice(len(imgsF5) - 1, int(len(imgsF5) * 0.8), replace=False)\n",
        "testIdxF5 = list(set(range(0, len(imgsF5))) - set(trainIdxF5))\n",
        "\n",
        "trainImgsF5 = imgsF5[trainIdxF5, :, :]\n",
        "testImgsF5 = imgsF5[testIdxF5, :, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtaG5p9lUcyq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainImgs = np.vstack([trainImgsF1, trainImgsF5])\n",
        "testImgs = np.vstack([testImgsF1, testImgsF5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainLabelF1 = np.stack((np.ones( int(len(imgsF1) * 0.8)), np.zeros( int(len(imgsF1) * 0.8))), axis = -1)\n",
        "testLabelF1 = np.stack((np.ones( int(len(imgsF1) * 0.2)), np.zeros( int(len(imgsF1) * 0.2))), axis = -1)\n",
        "\n",
        "trainLabelF5 = np.stack((np.zeros( int(len(imgsF5) * 0.8)), np.ones( int(len(imgsF5) * 0.8))), axis = -1)\n",
        "testLabelF5 = np.stack((np.zeros( int(len(imgsF5) * 0.2)), np.ones( int(len(imgsF5) * 0.2))), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelF1, trainLabelF5))\n",
        "Y_test = np.vstack((testLabelF1, testLabelF5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-m4Kq1y7YW0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ed3f721-5b2f-40cb-d795-38e8872d2daa"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwsOP0NKGnkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "9570ddfc-dcf6-4c59-d95f-61b58ab107ca"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "    input_tensor = Input(shape=(224, 224, 3))\n",
        "    \n",
        "    modelInceptionV3WoTop = None\n",
        "    modelInceptionV3 = None\n",
        "\n",
        "    modelInceptionV3WoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    # modelInceptionV3WoTop.summary()\n",
        "    # modelInceptionV3 = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n",
        "    # modelInceptionV3.summary()\n",
        "\n",
        "    modelInceptionV3 = Sequential()\n",
        "\n",
        "    modelInceptionV3.add(modelInceptionV3WoTop)\n",
        "    modelInceptionV3.add(GlobalAveragePooling2D())\n",
        "    modelInceptionV3.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # modelInceptionV3.summary()\n",
        "\n",
        "    modelInceptionV3.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    modelInceptionV3.fit(X_train, Y_train,\n",
        "              batch_size=4, epochs=6, verbose=1,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    \n",
        "    K.clear_session()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 7s 0us/step\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.2290 - acc: 0.9256 - val_loss: 7.2630e-04 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1245 - acc: 0.9537 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1036 - acc: 0.9581 - val_loss: 1.7228 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1022 - acc: 0.9688 - val_loss: 0.0102 - val_acc: 0.9950\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.6161e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 7.7242e-04 - acc: 1.0000 - val_loss: 8.5970e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fbcd3a95152f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m               validation_data=(X_test, Y_test))\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "I184FR1dvkb8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "for i in range(100):\n",
        "    \n",
        "    input_tensor = Input(shape=(224, 224, 3))\n",
        "    \n",
        "    modelVGG19WoTop = None\n",
        "    modelVGG19 = None\n",
        "\n",
        "    modelVGG19WoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "    modelVGG19 = Sequential()\n",
        "\n",
        "    modelVGG19.add(modelVGG19WoTop)\n",
        "    modelVGG19.add(Flatten())\n",
        "    modelVGG19.add(Dense(4096, activation='relu'))\n",
        "    modelVGG19.add(Dropout(0.5))\n",
        "    modelVGG19.add(Dense(4096, activation='relu'))\n",
        "    modelVGG19.add(Dropout(0.5))\n",
        "    \n",
        "#     modelVGG19.add(Dense(128, activation='relu'))\n",
        "#     modelVGG19.add(Dropout(0.5))\n",
        "#     modelVGG19.add(Dense(128, activation='relu'))\n",
        "#     modelVGG19.add(Dropout(0.5))\n",
        "    \n",
        "    modelVGG19.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    modelVGG19.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    modelVGG19.fit(X_train, Y_train,\n",
        "              batch_size=2, epochs=8, verbose=1,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    \n",
        "    K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOIMr0c6G3QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiWy-nF4RAFM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "modelVGG16WoTop = None\n",
        "modelVGG16 = None\n",
        "\n",
        "modelVGG16WoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "modelVGG16 = Sequential()\n",
        "\n",
        "modelVGG16.add(modelVGG16WoTop)\n",
        "modelVGG16.add(Flatten())\n",
        "modelVGG16.add(Dense(100, activation='relu'))\n",
        "modelVGG16.add(Dropout(0.5))\n",
        "modelVGG16.add(Dense(100, activation='relu'))\n",
        "modelVGG16.add(Dropout(0.5))\n",
        "\n",
        "modelVGG16.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelVGG16.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelVGG16.fit(X_train, Y_train,\n",
        "          batch_size=2, epochs=2, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEDNxMjPT34S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "modelResNet50WoTop = None\n",
        "modelResNet50 = None\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "modelResNet50WoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "modelResNet50 = Sequential()\n",
        "\n",
        "modelResNet50.add(modelResNet50WoTop)\n",
        "modelResNet50.add(Flatten())\n",
        "modelResNet50.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelResNet50.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelResNet50.fit(X_train, Y_train,\n",
        "          batch_size=4, epochs=8, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import datetime\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "modelResNet50.save('gdrive/My Drive/Colab/Model/ResNet50 {}.h5'.format(now.strftime('%m-%d %H:%M:%S')))\n",
        "# modelResNet50_ = load_model('gdrive/My Drive/Colab/Model/ResNet50.h5')\n",
        "\n",
        "# Y_pred = modelResNet50_.predict(X_test)\n",
        "# print(confusion_matrix(np.argmax(Y_pred, axis = 1), np.argmax(Y_test, axis = 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDhXm3brHs_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "TgKGs_zL0nwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i in range(1000, 1010):\n",
        "#     plt.figure()\n",
        "#     plt.imshow(X_train[i, :, :, 0]);\n",
        "#     plt.plot()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}